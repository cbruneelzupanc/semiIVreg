@misc{bruneel2024,
      title={Don't (fully) exclude me, it's not necessary! Identification with semi-IVs}, 
      author={Christophe Bruneel-Zupanc},
      year={2024},
      eprint={2303.12667},
      archivePrefix={arXiv},
      primaryClass={econ.EM}
}

@article{carneiroheckmanvytlacil2011,
 ISSN = {00028282},
 URL = {http://www.jstor.org/stable/23045657},
 author = {Pedro Carneiro and James J. Heckman and Edward J. Vytlacil},
 journal = {The American Economic Review},
 number = {6},
 pages = {2754--2781},
 publisher = {American Economic Association},
 title = {Estimating Marginal Returns to Education},
 urldate = {2023-02-26},
 volume = {101},
 year = {2011}
}

@article{heckmanhonore1990,
 ISSN = {00129682, 14680262},
 URL = {http://www.jstor.org/stable/2938303},
 abstract = {This paper clarifies and extends the classical Roy model of self selection and earnings inequality. The original Roy model, based on the assumption that log skills are normally distributed, is shown to imply that pursuit of comparative advantage in a free market reduces earnings inequality compared to the earnings distribution that would result if workers were randomly assigned to sectors. Aggregate log earnings are right skewed even if one sectoral distribution is left skewed. Most major implications of the log normal Roy model survive if differences in skills are log concave. However few implications of the model survive if skills are generated from more general distributions. We consider the identifiability of the Roy model from data on earnings distributions. The normal theory version is identifiable without regressors or exclusion restrictions. Sectoral distributions can be identified knowing only the aggregate earnings distribution. For general skill distributions, the model is not identified and has no empirical content. With sufficient price variation, the model can be identified from multimarket data. Cross-sectional variation in regressors can substitute for price variation in restoring empirical content to the Roy model.},
 author = {James J. Heckman and Bo E. Honoré},
 journal = {Econometrica},
 number = {5},
 pages = {1121--1149},
 publisher = {[Wiley, Econometric Society]},
 title = {The Empirical Content of the Roy Model},
 urldate = {2023-02-27},
 volume = {58},
 year = {1990}
}
@article{heckmanhonore1989,
 ISSN = {00063444},
 URL = {http://www.jstor.org/stable/2336666},
 abstract = {This paper considers the consequences for identifiability of introducing regressors into the competing risks model of multistate duration analysis. We establish conditions under which access to regressors overturns the nonidentification theorem of Cox and Tsiatis for both proportional and accelerated failure time models.},
 author = {James J. Heckman and Bo E. Honoré},
 journal = {Biometrika},
 number = {2},
 pages = {325--330},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {The Identifiability of the Competing Risks Model},
 urldate = {2023-02-27},
 volume = {76},
 year = {1989}
}
@incollection{heckmanvytlacil2007a,
title = {Chapter 70 Econometric Evaluation of Social Programs, Part I: Causal Models, Structural Models and Econometric Policy Evaluation},
editor = {James J. Heckman and Edward E. Leamer},
series = {Handbook of Econometrics},
publisher = {Elsevier},
volume = {6},
pages = {4779-4874},
year = {2007},
issn = {1573-4412},
doi = {https://doi.org/10.1016/S1573-4412(07)06070-9},
url = {https://www.sciencedirect.com/science/article/pii/S1573441207060709},
author = {James J. Heckman and Edward J. Vytlacil},
keywords = {causal models, counterfactuals, policy evaluation, policy invariance, structural models, identification},
abstract = {This chapter relates the literature on the econometric evaluation of social programs to the literature in statistics on “causal inference”. In it, we develop a general evaluation framework that addresses well-posed economic questions and analyzes agent choice rules and subjective evaluations of outcomes as well as the standard objective evaluations of outcomes. The framework recognizes uncertainty faced by agents and ex ante and ex post evaluations of programs. It also considers distributions of treatment effects. These features are absent from the statistical literature on causal inference. A prototypical model of agent choice and outcomes is used to illustrate the main ideas. We formally develop models for counterfactuals and causality that build on Cowles Commission econometrics. These models anticipate and extend the literature on causal inference in statistics. The distinction between fixing and conditioning that has recently entered the statistical literature was first developed by Cowles economists. Models of simultaneous causality were also developed by the Cowles group, as were notions of invariance to policy interventions. These basic notions are updated to nonlinear and nonparametric frameworks for policy evaluation more general than anything in the current statistical literature on “causal inference”. A formal discussion of identification is presented and applied to clearly formulated choice models used to evaluate social programs.}
}
@incollection{heckmanvytlacil2007b,
title = {Chapter 71 Econometric Evaluation of Social Programs, Part II: Using the Marginal Treatment Effect to Organize Alternative Econometric Estimators to Evaluate Social Programs, and to Forecast their Effects in New Environments},
editor = {James J. Heckman and Edward E. Leamer},
series = {Handbook of Econometrics},
publisher = {Elsevier},
volume = {6},
pages = {4875-5143},
year = {2007},
issn = {1573-4412},
doi = {https://doi.org/10.1016/S1573-4412(07)06071-0},
url = {https://www.sciencedirect.com/science/article/pii/S1573441207060710},
author = {James J. Heckman and Edward J. Vytlacil},
keywords = {marginal treatment effect, policy evaluation, instrumental variables, forecasting new policies, econometric cost benefit analysis, regression discontinuity, matching, bounds},
abstract = {This chapter uses the marginal treatment effect (MTE) to unify and organize the econometric literature on the evaluation of social programs. The marginal treatment effect is a choice-theoretic parameter that can be interpreted as a willingness to pay parameter for persons at a margin of indifference between participating in an activity or not. All of the conventional treatment parameters as well as the more economically motivated treatment effects can be generated from a baseline marginal treatment effect. All of the estimation methods used in the applied evaluation literature, such as matching, instrumental variables, regression discontinuity methods, selection and control function methods, make assumptions about the marginal treatment effect which we exposit. Models for multiple outcomes are developed. Empirical examples of the leading methods are presented. Methods are presented for bounding treatment effects in partially identified models, when the marginal treatment effect is known only over a limited support. We show how to use the marginal treatment in econometric cost benefit analysis, in defining limits of policy experiments, in constructing the average marginal treatment effect, and in forecasting the effects of programs in new environments.}
}
@article{heckman2006understanding,
  title={Understanding instrumental variables in models with essential heterogeneity},
  author={Heckman, James J and Urzua, Sergio and Vytlacil, Edward},
  journal={The review of economics and statistics},
  volume={88},
  number={3},
  pages={389--432},
  year={2006},
  publisher={The MIT Press}
}
@article{heckmanvytlacil2005,
 ISSN = {00129682, 14680262},
 URL = {http://www.jstor.org/stable/3598865},
 abstract = {This paper uses the marginal treatment effect (MTE) to unify the nonparametric literature on treatment effects with the econometric literature on structural estimation using a nonparametric analog of a policy invariant parameter; to generate a variety of treatment effects from a common semiparametric functional form; to organize the literature on alternative estimators; and to explore what policy questions commonly used estimators in the treatment effect literature answer. A fundamental asymmetry intrinsic to the method of instrumental variables (IV) is noted. Recent advances in IV estimation allow for heterogeneity in responses but not in choices, and the method breaks down when both choice and response equations are heterogeneous in a general way.},
 author = {James J. Heckman and Edward Vytlacil},
 journal = {Econometrica},
 number = {3},
 pages = {669--738},
 publisher = {[Wiley, Econometric Society]},
 title = {Structural Equations, Treatment Effects, and Econometric Policy Evaluation},
 urldate = {2023-04-11},
 volume = {73},
 year = {2005}
}

@incollection{frenchtaber2011,
title = {Chapter 6 - Identification of Models of the Labor Market},
editor = {Orley Ashenfelter and David Card},
series = {Handbook of Labor Economics},
publisher = {Elsevier},
volume = {4},
pages = {537-617},
year = {2011},
issn = {1573-4463},
doi = {https://doi.org/10.1016/S0169-7218(11)00412-6},
url = {https://www.sciencedirect.com/science/article/pii/S0169721811004126},
author = {Eric French and Christopher Taber},
keywords = {Identification, Roy model, Discrete choice, Selection, Treatment effects},
abstract = {This chapter discusses identification of common selection models of the labor market. We start with the classic Roy model and show how it can be identified with exclusion restrictions. We then extend the argument to the generalized Roy model, treatment effect models, duration models, search models, and dynamic discrete choice models. In all cases, key ingredients for identification are exclusion restrictions and support conditions.}
}

@article{andresen2018exploring,
  title={Exploring marginal treatment effects: Flexible estimation using Stata},
  author={Andresen, Martin Eckhoff},
  journal={The Stata Journal},
  volume={18},
  number={1},
  pages={118--158},
  year={2018},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@article{brinch2017beyond,
  title={Beyond LATE with a discrete instrument},
  author={Brinch, Christian N and Mogstad, Magne and Wiswall, Matthew},
  journal={Journal of Political Economy},
  volume={125},
  number={4},
  pages={985--1039},
  year={2017},
  publisher={University of Chicago Press Chicago, IL}
}

@article{chernozhukov2005iv,
  title={An IV model of quantile treatment effects},
  author={Chernozhukov, Victor and Hansen, Christian},
  journal={Econometrica},
  volume={73},
  number={1},
  pages={245--261},
  year={2005},
  publisher={Wiley Online Library}
}

@article{robinson1988root,
  title={Root-N-consistent semiparametric regression},
  author={Robinson, Peter M},
  journal={Econometrica: Journal of the Econometric Society},
  pages={931--954},
  year={1988},
  publisher={JSTOR}
}
@book{fangijbels2003,
author = {Fan, Jianqing. and Gijbels, Irène.},
address = {Boca Raton},
isbn = {0-412-98321-4},
keywords = {Nonparametric statistics},
language = {eng},
publisher = {Chapman and Hall/CRC},
series = {Monographs on statistics and applied probability 66},
title = {Local polynomial modelling and its applications.},
year = {1996},
}
@article{nprobust,
 title={nprobust: Nonparametric Kernel-Based Estimation and Robust Bias-Corrected Inference},
 volume={91},
 url={https://www.jstatsoft.org/index.php/jss/article/view/v091i08},
 doi={10.18637/jss.v091.i08},
 abstract={Nonparametric kernel density and local polynomial regression estimators are very popular in statistics, economics, and many other disciplines. They are routinely employed in applied work, either as part of the main empirical analysis or as a preliminary ingredient entering some other estimation or inference procedure. This article describes the main methodological and numerical features of the software package nprobust, which offers an array of estimation and inference procedures for nonparametric kernel-based density and local polynomial regression methods, implemented in both the R and Stata statistical platforms. The package includes not only classical bandwidth selection, estimation, and inference methods (Wand and Jones 1995; Fan and Gijbels 1996), but also other recent developments in the statistics and econometrics literatures such as robust bias-corrected inference and coverage error optimal bandwidth selection (Calonico, Cattaneo, and Farrell 2018, 2019a). Furthermore, this article also proposes a simple way of estimating optimal bandwidths in practice that always delivers the optimal mean square error convergence rate regardless of the specific evaluation point, that is, no matter whether it is implemented at a boundary or interior point. Numerical performance is illustrated using an empirical application and simulated data, where a detailed numerical comparison with other R packages is given.},
 number={8},
 journal={Journal of Statistical Software},
 author={Calonico, Sebastian and Cattaneo, Matias D. and Farrell, Max H.},
 year={2019},
 pages={1–33}
}
@book{wand1994kernel,
  title={Kernel smoothing},
  author={Wand, Matt P and Jones, M Chris},
  year={1994},
  publisher={CRC press}
}

