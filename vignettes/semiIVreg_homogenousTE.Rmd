---
title: "Estimator Performance: homogenous treatment effect model"
author: "[Christophe Bruneel-Zupanc](https://www.cbruneel.com/)"
date: "Last modified: 2024-07-22"
output:
  rmarkdown::html_vignette:
    highlight: monochrome
    toc: true
  rmarkdown::html_document:
    toc: true
    toc_depth: 2
  pdf_document:
    highlight: monochrome
bibliography: semiIVreg.bib
biblio-style: "apalike"
vignette: >
  %\VignetteKeywords{instrumental variables, semi-IVs, causal inference}
  %\VignetteEncoding{UTF-8}
  %\VignetteIndexEntry{Estimator Performance: homogenous treatment effect model}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>", echo = TRUE, fig.retina = 2#,#fig.height=4, fig.width=5, fig.align='center'
)
if (!requireNamespace("ivreg", quietly = TRUE)) {
  install.packages("ivreg")
}
library(ivreg)
options(scipen=8)
```


Let us compare the performance of the semi-IV estimator under different violation of the standard IV assumptions. 
This note mimics the Appendix on @bruneel2024. 

## Simulating data

We simulate generalized Roy models using the `simul_data()`function. 
See the documentation of the function for details about the model. Depending on the chosen parameters, we can simulate a model with homogenous/heterogenous treatment effects, as well as with valid IVs eventually. That's what we will do here. 
In every simulation we do not include covariates (set all their effect to 0), but these can be easily included. 


## Model with homogenous treatment effects

### Simulate data

```{r model1} 
# Model 1
library(semiIVreg)
N = 10000; set.seed(1234)
model_type = "homogenous"
param_error = c(1, 1.5, -0.6) # var_u, var_v, cov_uv # if homogenous
param_Z = c(0, 0, 0, 0, 1.5, 1.5, 0.9) # meanW0 state0, meanW1 state0, meanW0 state1, meanW1 state1, varW0, varW1, covW0W1
param_p = c(0, -0.5, 0.5, 0, 0, 0) # constant, alphaW0, alphaW1, alphaW0W1, effect of state, effect of parent educ
param_y0 = c(3.2, 0.8, 0, 0) # intercept, effect of Wd, effect of state, effect of parent educ;
param_y1 = c(3.2+0.4, 0.5, 0, 0) # the +0.2 = Average treatment effect; effect of W1, effect of state, effect of parent educ;
param_genX = c(0.4, 0, 2) # probability state=1 (instead of 0), mean_parenteduc, sd_parenteduc (parenteduc drawn as continuous)

data = simul_data(N, model_type, param_y0, param_y1, param_p, param_Z, param_genX, param_error)
```

This is a model with homogenous Treatment Effects (conditional on \(W_0, W_1\)). 

### True unobserved homogenous Treatment Effects

Here, at \((W_0, W_1) = (0, 0)\), the effect is always 0.4 (see the parameters). To see this, let us just use the true *unobserved* potential outcomes (only observed thanks to the simulation). 

```{r model1true}
data$true_TE = data$y1 - data$y0
summary(lm(true_TE ~ w0 + w1, data))
true_param = c(param_y0[1], param_y1[1] - param_y0[1], param_y0[2], param_y1[2]); true_param
# constant y0, constant y1 - constant y0, effects of w0 on y0, effects of w1 on y1.
```

This is the true model that we would like to recover. Note that it is a perfect fit because it is exactly the same error term in both potential outcomes, $U_0 = U_1 = U$. If we had an additional error term but uncorrelated with the rest, we would estimate the same coefficients (but with more noise). 


### Naive OLS

```{r naiveols1}
naive_ols = lm(y ~ d + w0 + w1, data); summary(naive_ols)
```

Obviously, the naive OLS estimator is biased, because there is endogeneity: $U$ is correlated with $D$ and $Y$. It overestimates the effect of the treatment $D$ to be `r round(coefficients(naive_ols)[2])`. This is because individuals with high $U$ both select themself more into $D=1$ and have a higher $Y$. Indeed $E(U | D=1) > E(U | D=0)$, and $U$ is negatively correlated with $V$ (cf the covariance parameter in `param_error`), so the higher $U$, the lower $V$, and the lower $V$, the more likely one is to select $D=1$.   

```{r selectionbias1}
mean(data$U1[which(data$d == 1)]); mean(data$U0[which(data$d==0)])
```


### Wrongly assuming that the semi-IVs are valid IVs

What is we assume that $W_0$ and $W_1$ are valid IVs (i.e., that they have no direct effect on their respective potential outcomes)? 

```{r ivreg1}
library(ivreg) # remark: ivreg is not required otherwise in semiivreg, only in this vignette. 
valid_iv = ivreg(y ~ d | w0 + w1 + w0:w1, data=data); summary(valid_iv)
```

The estimated coefficients is also completely biased here, because it assumes the semi-IVs have no effect on the outcomes while they do. 



### semi-IV estimation with `semiivreg`

Let us now see how the semi-IV estimator performs. To specify the estimation with homogenous treatment effects, we specify `est_method="homogenous"`. This performs a sieve-like estimation but with an additional constraint which restrict the MTE to be constant by imposing constraints on the control function $\kappa_0(p)$ and $\kappa_1(p)$.  

```{r semiiv1}
semiiv = semiivreg(y~d|w0|w1, data, est_method="homogenous", plotting=FALSE)
semiiv_homogenous = semiiv$estimate$est # extract the coefficients from the homogenous TE specification
summary_coeff = summary(semiiv_homogenous)
summary_coeff$coefficients[1:4,] # only print the first 4 coefficients, the other correspond to the control function of P
true_param
```

The estimated coefficients are very close to the truth, with relatively small standard errors here, even though the sample size is modest (`r N` observations). 

Be cautious though: the standard errors are computed *without* taking into account the fact that the propensity score is estimated in a first stage. We can correct this estimation with `semiivreg_boot()`. But typically, if the first stage is well estimated, the bias in the standard errors is small, as visible below. 
<!-- , cache=TRUE} --> 
```{r semiivboot1} 
semiivboot = semiivreg_boot(y~d|w0|w1, data, Nboot=100, est_method="homogenous", plotting=FALSE) # reduce the number of bootstrap simulation for speed;  
boot_se = semiivboot$estimate$coeff$std_error[1:4]
res = as.data.frame(cbind(summary_coeff$coefficients[1:4,1:2], boot_se)); colnames(res) = c("Estimate", "wrong analytic SE", "Bootstrapped SE")
res
```





### Alternative semi-IV strategy: based on IV-quantile regression
As described in @bruneel2024, there is another general nonparametric identification strategy with semi-IV, building on the IV-quantile regression (IVQR) framework of @chernozhukov2005iv. In the model with homogenous treatment effect, this strategy requires that some interaction $W_0 \times W_1$ is relevant for the selection into treatment. The intuition is that this interaction now serves as IV for the treatment $D$ within this framework. The nice feature of this strategy is that it can be implemented with standard IV estimation, e.g., `ivreg()` in R.  

```{r semiivqr}
semiivqr = ivreg(y~d+I(1-d):w0 + I(d):w1|w0+w1+w0:w1, data=data)
summary(semiivqr)
```

In this baseline model, the interaction is not significant in the first stage, so we have a problem of weak IVs. 
This is not the case in this baseline model, so the estimation blow up because the IV is irrelevant. 


However, if we specify an alternative model where the interaction is indeed relevant, we will also estimate correctly the homogenous treatment effect using this strategy. This is what we do now. 

```{r model2} 
# Model 2
N = 10000; set.seed(1234)
model_type = "homogenous"
param_error = c(1, 1.5, -0.6) # var_u, var_v, cov_uv # if homogenous
param_Z = c(0, 0, 0, 0, 1.5, 1.5, 0.9) # meanW0 state0, meanW1 state0, meanW0 state1, meanW1 state1, varW0, varW1, covW0W1
param_p = c(0, -0.3, 0.4, 0.3, 0, 0) # constant, alphaW0, alphaW1, alphaW0W1, effect of state, effect of parent educ
param_y0 = c(3.2, 0.8, 0, 0) # intercept, effect of Wd, effect of state, effect of parent educ;
param_y1 = c(3.2+0.4, 0.5, 0, 0) # the +0.2 = Average treatment effect; effect of W1, effect of state, effect of parent educ;
param_genX = c(0.4, 0, 2) # probability state=1 (instead of 0), mean_parenteduc, sd_parenteduc (parenteduc drawn as continuous)

data2 = simul_data(N, model_type, param_y0, param_y1, param_p, param_Z, param_genX, param_error)
```

This is a model `param_p[4]` gives the effect of $W_0\times W_1$ on $D$. It is different from 0 here. So the IVQR strategy should work. 

```{r semiivqr2}
semiivqr2 = ivreg(y~d+I(1-d):w0 + I(d):w1|w0+w1+w0:w1, data=data2); summary(semiivqr2)
```

Indeed, it estimates the coefficients well. 
Notice that the `semiivreg()` function also works there: 

```{r semiivreg2}
semiiv2 = semiivreg(y~d|w0|w1, data=data2, est_method="homogenous", plotting=FALSE)
semiiv2_homogenous = semiiv2$estimate$est # extract the coefficients from the homogenous TE specification
summary_coeff2 = summary(semiiv2_homogenous)
summary_coeff2$coefficients[1:4,] # only print the first 4 coefficients, the other correspond to the control function of P
true_param
```

Thus `semiivreg()`is more flexible and should be used in any case. Notice that, in general the IVQR estimation will also have a higher variance of the estimate because it builds on the interaction as an IV so it requires it to have a large significant effects on the treatment to avoid weak IV concerns. 
While the `semiivreg()` only relies on the fact that each semi-IV is relevant by itself, which is relatively easier to satisfy. Especially if the semi-IVs have a strong impact on their respective potential outcome, they should be relevant as soon as there is selection into treatment based on gains (i.e., $Y_1 - Y_0$). 



## References


