<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>semiIVreg: R package for semi-IV regression ‚Ä¢ semiIVreg</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="semiIVreg: R package for semi-IV regression">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="default" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">semiIVreg</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../index.html">Get started</a></li>
<li class="active nav-item"><a class="nav-link" href="../articles/semiIVreg.html">Model and Guidelines</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-more" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">More</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-more">
<li><a class="dropdown-item" href="../articles/semiIVreg_homogenousTE.html">Estimation with Homogenous Treatment Effect</a></li>
    <li><a class="dropdown-item" href="../articles/semiIVreg_heterogenousTE.html">Estimation with general Heterogenous Treatment Effect</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://twitter.com/CBruneelZupanc" aria-label="Twitter"><span class="fa fa-twitter"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/cbruneelzupanc/semiIVreg" aria-label="Github"><span class="fa fa-github"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>semiIVreg: R package for semi-IV regression</h1>
                        <h4 data-toc-skip class="author"><a href="https://www.cbruneel.com/" class="external-link">Christophe Bruneel-Zupanc</a></h4>
            
            <h4 data-toc-skip class="date">last modified:
2024-10-26</h4>
      

      <div class="d-none name"><code>semiIVreg.Rmd</code></div>
    </div>

    
    
<!--

``` r
library(semiIVreg)
#> KernSmooth 2.23 loaded
#> Copyright M. P. Wand 1997-2009
```
-->
<div class="section level2">
<h2 id="overview">Overview<a class="anchor" aria-label="anchor" href="#overview"></a>
</h2>
<!-- <center>
![](images/causal_graph.png)
</center> -->
<p>This package provides estimation procedure with semi-IVs, as in <span class="citation">Bruneel-Zupanc (2024)</span>.<br>
In particular, the main function <code><a href="../reference/semiivreg.html">semiivreg()</a></code> estimates the
marginal treatment effect (MTE) and marginal treatment response
(MTR).</p>
<div style="text-align: center;">
<p><img src="images/causal_graph.png" alt="" width="400"></p>
</div>
</div>
<div class="section level2">
<h2 id="installation">Installation<a class="anchor" aria-label="anchor" href="#installation"></a>
</h2>
<p>The development version of <strong>semiIVreg</strong> is hosted on
GitHub <a href="https://github.com/cbruneelzupanc/semiIVreg/" class="external-link">here</a>.
It can be conveniently installed via the <code>install_github()</code>
function from the <a href="https://CRAN.R-project.org/package=remotes" class="external-link">remotes</a>
package.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">remotes</span><span class="fu">::</span><span class="fu"><a href="https://remotes.r-lib.org/reference/install_github.html" class="external-link">install_github</a></span><span class="op">(</span><span class="st">"cbruneelzupanc/semiIVreg"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="semi-instrumental-variable-semi-iv-regression">semi-instrumental variable (semi-IV) regression<a class="anchor" aria-label="anchor" href="#semi-instrumental-variable-semi-iv-regression"></a>
</h2>
</div>
<div class="section level2">
<h2 id="the-model">The model<a class="anchor" aria-label="anchor" href="#the-model"></a>
</h2>
<p><code>semiivreg</code> estimates the marginal treatment effect (MTE)
and marginal treatment response (MTR) of the following model.</p>
<p>The potential outcomes are given by the semi-parametric model:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Y</mi><mn>0</mn></msub><mo>=</mo><msub><mi>Œ¥</mi><mn>0</mn></msub><mo>+</mo><msub><mi>W</mi><mn>0</mn></msub><msub><mi>Œ≤</mi><mn>0</mn></msub><mo>+</mo><mi>X</mi><msubsup><mi>Œ≤</mi><mn>0</mn><mi>X</mi></msubsup><mo>+</mo><msub><mi>U</mi><mn>0</mn></msub><mo>,</mo><mspace width="1.0em"></mspace><mspace width="1.0em"></mspace><mspace width="1.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
Y_0 = \delta_{0} + W_0 \beta_0 + X \beta^X_{0} + U_0, \quad \quad \quad (1)
</annotation></semantics></math></p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Y</mi><mn>1</mn></msub><mo>=</mo><msub><mi>Œ¥</mi><mn>1</mn></msub><mo>+</mo><msub><mi>W</mi><mn>1</mn></msub><msub><mi>Œ≤</mi><mn>1</mn></msub><mo>+</mo><mi>X</mi><msubsup><mi>Œ≤</mi><mn>1</mn><mi>X</mi></msubsup><mo>+</mo><msub><mi>U</mi><mn>1</mn></msub><mo>,</mo><mspace width="1.0em"></mspace><mspace width="1.0em"></mspace><mspace width="1.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mn>2</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
Y_1 = \delta_{1} + W_1 \beta_1 + X \beta^X_{1} + U_1, \quad \quad \quad (2)
</annotation></semantics></math></p>
<p>with selection rule</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><msup><mi>D</mi><mo>*</mo></msup></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>W</mi><mn>0</mn></msub><mo>,</mo><msub><mi>W</mi><mn>1</mn></msub><mo>,</mo><mi>X</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àí</mo><mi>V</mi></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mo>‚àí</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ±</mi><mo>+</mo><msub><mi>Œ±</mi><mn>0</mn></msub><msub><mi>W</mi><mn>0</mn></msub><mo>+</mo><msub><mi>Œ±</mi><mn>1</mn></msub><msub><mi>W</mi><mn>1</mn></msub><mo>+</mo><msub><mi>Œ±</mi><mi>X</mi></msub><mi>X</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àí</mo><mi>V</mi><mo>,</mo><mspace width="1.0em"></mspace><mspace width="1.0em"></mspace><mspace width="1.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mn>3</mn><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"><mrow><mspace width="0.333em"></mspace><mtext mathvariant="normal"> with </mtext><mspace width="0.333em"></mspace></mrow><mspace width="1.0em"></mspace><mi>D</mi></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mi>ùïÄ</mi><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>D</mi><mo>*</mo></msup><mo>&gt;</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
D^* &amp;= g(W_0, W_1, X) - V \\
&amp;= - (\alpha + \alpha_0 W_0 + \alpha_1 W_1 + \alpha_{X} X ) - V, \quad \quad \quad (3) \\
\text{ with } \quad D &amp;= \mathbb{I}(D^* &gt; 0),
\end{aligned}
</annotation></semantics></math></p>
<p>where</p>
<ul>
<li><p><strong>semi-IVs</strong>:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>W</mi><mn>0</mn></msub><annotation encoding="application/x-tex">W_0</annotation></semantics></math>
(respectively
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>W</mi><mn>1</mn></msub><annotation encoding="application/x-tex">W_1</annotation></semantics></math>)
are the semi-IVs excluded from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Y</mi><mn>1</mn></msub><annotation encoding="application/x-tex">Y_1</annotation></semantics></math>
(resp.
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Y</mi><mn>0</mn></msub><annotation encoding="application/x-tex">Y_0</annotation></semantics></math>).
Each
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>W</mi><mn>0</mn></msub><annotation encoding="application/x-tex">W_0</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>W</mi><mn>1</mn></msub><annotation encoding="application/x-tex">W_1</annotation></semantics></math>
may contain several variables. Nonparametric identification requires
that each
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>W</mi><mi>d</mi></msub><annotation encoding="application/x-tex">W_d</annotation></semantics></math>
contains <em>at least one excluded variable</em> (see <span class="citation">Bruneel-Zupanc (2024)</span>).</p></li>
<li><p><strong>Covariates</strong>:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
are the covariates that affect both potential outcomes. By default,
different effect of the covariates across alternatives, (i.e.,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>Œ≤</mi><mn>0</mn><mi>X</mi></msubsup><mo>‚â†</mo><msubsup><mi>Œ≤</mi><mn>1</mn><mi>X</mi></msubsup></mrow><annotation encoding="application/x-tex">\beta^X_{0} \neq \beta^X_{1}</annotation></semantics></math>).
To do so, include the covariates separately in both MTR formulas:
<code>semiivreg(y~d|w0+x|w1+x, data)</code>. One can restrict the effect
of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
to be the same across both potential outcomes (i.e.,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>Œ≤</mi><mn>0</mn><mi>X</mi></msubsup><mo>=</mo><msubsup><mi>Œ≤</mi><mn>1</mn><mi>X</mi></msubsup></mrow><annotation encoding="application/x-tex">\beta^X_{0} = \beta^X_{1}</annotation></semantics></math>).
To do so, specify: <code>semiivreg(y~d|w0|w1|x, data)</code>.</p></li>
<li><p><strong>Unobservables</strong>:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>U</mi><mn>0</mn></msub><annotation encoding="application/x-tex">U_0</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>U</mi><mn>1</mn></msub><annotation encoding="application/x-tex">U_1</annotation></semantics></math>
are general unobservables (may include several shocks, some may be the
same across alternatives) affecting the outcomes. Generally normalize
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>U</mi><mi>d</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>X</mi><mo>,</mo><msub><mi>W</mi><mi>d</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">E(U_d | X, W_d)=0</annotation></semantics></math>.
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>V</mi><annotation encoding="application/x-tex">V</annotation></semantics></math>
is a scalar unobservable that affects the selection. The lower
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>V</mi><annotation encoding="application/x-tex">V</annotation></semantics></math>,
the more likely one is to select into treatment. Nonparametric
identification requires <em>independence</em>, i.e.,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>U</mi><mn>0</mn></msub><mo>,</mo><msub><mi>U</mi><mn>1</mn></msub><mo>,</mo><mi>V</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚ä•</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>W</mi><mn>0</mn></msub><mo>,</mo><msub><mi>W</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="false" form="prefix">|</mo><mi>X</mi></mrow><annotation encoding="application/x-tex">(U_0, U_1, V) \perp (W_0, W_1) | X</annotation></semantics></math>.<br>
For estimation here, we additionally assume additive
<em>separability</em> of the covariates
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>,
i.e., that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>U</mi><mi>d</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>V</mi><mo>,</mo><mi>X</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>U</mi><mi>d</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>V</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">E(U_d | V, X) = E(U_d | V)</annotation></semantics></math>
for both
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo>=</mo><mn>0</mn><mo>,</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">d=0,1</annotation></semantics></math>.<br>
This assumption is <em>not necessary</em> for the identification, nor
for the estimation. But it is a standard <em>simplification</em> that
helps the estimation. See <span class="citation">Carneiro, Heckman, and
Vytlacil (2011)</span>, <span class="citation">Brinch, Mogstad, and
Wiswall (2017)</span> or <span class="citation">Andresen (2018)</span>
for comparable examples of the estimation of MTE with IVs.</p></li>
</ul>
<p><em>Remark about the flexibility of the model:</em> note that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>W</mi><mn>0</mn></msub><annotation encoding="application/x-tex">W_0</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>W</mi><mn>1</mn></msub><annotation encoding="application/x-tex">W_1</annotation></semantics></math>
can be flexible transformations (polynomial, splines) of specific
variables, so the outcome equations are quite flexible (could also
specify interactions between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>W</mi><mi>d</mi></msub><annotation encoding="application/x-tex">W_d</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>).
The semi-parametric model main assumption here is the separability
between the unobservables and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>,</mo><msub><mi>W</mi><mi>d</mi></msub></mrow><annotation encoding="application/x-tex">X, W_d</annotation></semantics></math>,
otherwise the model is as general as it can be.</p>
</div>
<div class="section level2">
<h2 id="estimation-procedure">Estimation procedure<a class="anchor" aria-label="anchor" href="#estimation-procedure"></a>
</h2>
<p>The estimation procedure closely follows the counterpart estimation
of MTE with standard IVs, see for e.g., Andresen (2018). The command
estimates <strong>Marginal Treatment Responses</strong>
(<strong>MTR</strong>) and <strong>Marginal Treatment Effects</strong>
(<strong>MTE</strong>). Define the normalized unobserved resistance to
treatment
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>U</mi><mi>D</mi></msub><mo>=</mo><msub><mi>F</mi><mi>V</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>V</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àº</mo><mi>U</mi><mi>n</mi><mi>i</mi><mi>f</mi><mi>o</mi><mi>r</mi><mi>m</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">U_D = F_V(V) \sim Uniform(0, 1)</annotation></semantics></math>.
Then, the MTRs are given by:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><mi>M</mi><mi>T</mi><msub><mi>R</mi><mi>d</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo>,</mo><msub><mi>w</mi><mi>d</mi></msub><mo>,</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>Y</mi><mi>d</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>X</mi><mo>=</mo><mi>x</mi><mo>,</mo><msub><mi>W</mi><mi>d</mi></msub><mo>=</mo><msub><mi>w</mi><mi>d</mi></msub><mo>,</mo><msub><mi>U</mi><mi>D</mi></msub><mo>=</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><msub><mi>Œ¥</mi><mi>d</mi></msub><mo>+</mo><msub><mi>W</mi><mi>d</mi></msub><msub><mi>Œ≤</mi><mi>d</mi></msub><mo>+</mo><mi>X</mi><msubsup><mi>Œ≤</mi><mi>d</mi><mi>X</mi></msubsup><mo>+</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>U</mi><mi>d</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>X</mi><mo>=</mo><mi>x</mi><mo>,</mo><msub><mi>W</mi><mi>d</mi></msub><mo>=</mo><msub><mi>w</mi><mi>d</mi></msub><mo>,</mo><msub><mi>U</mi><mi>D</mi></msub><mo>=</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><msub><mi>Œ¥</mi><mi>d</mi></msub><mo>+</mo><msub><mi>W</mi><mi>d</mi></msub><msub><mi>Œ≤</mi><mi>d</mi></msub><mo>+</mo><mi>X</mi><msubsup><mi>Œ≤</mi><mi>d</mi><mi>X</mi></msubsup><mo>+</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>U</mi><mi>d</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>U</mi><mi>D</mi></msub><mo>=</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><msub><mi>Œ¥</mi><mi>d</mi></msub><mo>+</mo><msub><mi>W</mi><mi>d</mi></msub><msub><mi>Œ≤</mi><mi>d</mi></msub><mo>+</mo><mi>X</mi><msubsup><mi>Œ≤</mi><mi>d</mi><mi>X</mi></msubsup><mo>+</mo><msub><mi>k</mi><mi>d</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
MTR_d(u, w_d, x) &amp;= E(Y_d | X=x, W_d=w_d, U_D=u) \\
&amp;= \delta_{d} + W_d \beta_d + X \beta^X_{d} + E(U_d|X=x, W_d=w_d, U_D=u) \\
&amp;= \delta_{d} + W_d \beta_d + X \beta^X_{d} + E(U_d|U_D=u) \\
&amp;= \delta_{d} + W_d \beta_d + X \beta^X_{d} + k_d(u),
\end{aligned}
</annotation></semantics></math> where the last equalities comes from
the fact that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>U</mi><mi>d</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>X</mi><mo>=</mo><mi>x</mi><mo>,</mo><msub><mi>W</mi><mi>d</mi></msub><mo>=</mo><msub><mi>w</mi><mi>d</mi></msub><mo>,</mo><msub><mi>U</mi><mi>D</mi></msub><mo>=</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>U</mi><mi>d</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>U</mi><mi>D</mi></msub><mo>=</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">E(U_d|X=x, W_d=w_d, U_D=u) = E(U_d|U_D=u)</annotation></semantics></math>
by the separability and independence, and then we just define
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>k</mi><mi>d</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>U</mi><mi>d</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>U</mi><mi>D</mi></msub><mo>=</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">k_d(u) = E(U_d|U_D=u)</annotation></semantics></math>.</p>
<p>Then, the Marginal Treatment Effects (MTE) are given by
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><mi>M</mi><mi>T</mi><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo>,</mo><mi>x</mi><mo>,</mo><msub><mi>w</mi><mn>0</mn></msub><mo>,</mo><msub><mi>w</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>Y</mi><mn>1</mn></msub><mo>‚àí</mo><msub><mi>Y</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">|</mo><mi>X</mi><mo>=</mo><mi>x</mi><mo>,</mo><msub><mi>W</mi><mn>0</mn></msub><mo>=</mo><msub><mi>w</mi><mn>0</mn></msub><mo>,</mo><msub><mi>W</mi><mn>1</mn></msub><mo>=</mo><msub><mi>w</mi><mn>1</mn></msub><mo>,</mo><msub><mi>U</mi><mi>D</mi></msub><mo>=</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mi>M</mi><mi>T</mi><msub><mi>R</mi><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo>,</mo><msub><mi>w</mi><mn>1</mn></msub><mo>,</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àí</mo><mi>M</mi><mi>T</mi><msub><mi>R</mi><mn>0</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo>,</mo><msub><mi>w</mi><mn>0</mn></msub><mo>,</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
MTE(u, x, w_0, w_1) &amp;= E(Y_1 - Y_0 | X = x, W_0=w_0, W_1=w_1, U_D=u) \\
&amp;= MTR_1(u, w_1, x) - MTR_0(u, w_0, x).
\end{aligned}
</annotation></semantics></math></p>
<p>Remark: the MTR and MTE are estimated at given covariates and
semi-IVs,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mi>X</mi><mo>,</mo><msub><mi>W</mi><mn>0</mn></msub><mo>,</mo><msub><mi>W</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(X, W_0, W_1)</annotation></semantics></math>.
This is specified using <code>ref_indiv</code>. Or by default, it
computes the ‚Äòaverage individual‚Äô (and take reference level for
factor).</p>
<p>The estimation proceeds in two stages: first estimate the propensity
to be treated,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>P</mi><annotation encoding="application/x-tex">P</annotation></semantics></math>,
and then the potential outcome treatment parameters.</p>
<div class="section level3">
<h3 id="st-stage-propensity-score">1st stage: propensity score<a class="anchor" aria-label="anchor" href="#st-stage-propensity-score"></a>
</h3>
<p>Estimate the propensity score
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>P</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\widehat{P}</annotation></semantics></math>
of treatment selection of equation (3).<br>
By default, the function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>‚ãÖ</mo><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">g(\cdot)</annotation></semantics></math>
is given by the simple linear specification above, but the code allows
specifying any other first stage. For example:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="fu"><a href="../reference/semiivreg.html">semiivreg</a></span><span class="op">(</span><span class="va">y</span><span class="op">~</span><span class="va">d</span><span class="op">|</span><span class="va">w0</span><span class="op">+</span><span class="va">x</span><span class="op">|</span><span class="va">w1</span><span class="op">+</span><span class="va">x</span>, <span class="va">data</span>,</span>
<span>            propensity_formula <span class="op">=</span> <span class="va">d</span><span class="op">~</span><span class="va">w0</span><span class="op">+</span><span class="va">w1</span><span class="op">+</span><span class="va">w0</span><span class="op">:</span><span class="va">w1</span><span class="op">+</span><span class="va">w0</span><span class="op">:</span><span class="va">x</span><span class="op">+</span><span class="va">w1</span><span class="op">:</span><span class="va">x</span><span class="op">+</span><span class="fu"><a href="https://rdrr.io/r/base/AsIs.html" class="external-link">I</a></span><span class="op">(</span><span class="va">w0</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">+</span><span class="fu"><a href="https://rdrr.io/r/base/AsIs.html" class="external-link">I</a></span><span class="op">(</span><span class="va">w1</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>By default, the estimation assumes a <em>probit model</em> for the
first stage (i.e., assumes
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>V</mi><annotation encoding="application/x-tex">V</annotation></semantics></math>
is normally distributed). However, you can specify other models (e.g.,
logit) using the <code>firststage_model</code> argument. In theory, any
specification for the first stage could be added, and it is even
possible to estimate the propensity score outside of the
<code>semiivreg</code> command (this feature is not implemented yet).
<br><br></p>
</div>
<div class="section level3">
<h3 id="nd-stage-marginal-treatment-responses">2nd stage: marginal treatment responses<a class="anchor" aria-label="anchor" href="#nd-stage-marginal-treatment-responses"></a>
</h3>
<div class="section level4">
<h4 id="estimated-objects">Estimated objects<a class="anchor" aria-label="anchor" href="#estimated-objects"></a>
</h4>
<p>First, given estimated
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>P</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\widehat{P}</annotation></semantics></math>,
the second stage estimates the following semi-parametric
<strong>partially linear model</strong> for the potential outcomes
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>Y</mi><mo stretchy="false" form="prefix">|</mo><mi>D</mi><mo>=</mo><mn>0</mn><mo>,</mo><msub><mi>W</mi><mn>0</mn></msub><mo>,</mo><mi>X</mi><mo>,</mo><mover><mi>P</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">]</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><msub><mi>Œ¥</mi><mn>0</mn></msub><mo>+</mo><msub><mi>W</mi><mn>0</mn></msub><msub><mi>Œ≤</mi><mn>0</mn></msub><mo>+</mo><mi>X</mi><msubsup><mi>Œ≤</mi><mn>0</mn><mi>X</mi></msubsup><mo>+</mo><msub><mi>Œ∫</mi><mn>0</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>P</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>Y</mi><mo stretchy="false" form="prefix">|</mo><mi>D</mi><mo>=</mo><mn>0</mn><mo>,</mo><msub><mi>W</mi><mn>1</mn></msub><mo>,</mo><mi>X</mi><mo>,</mo><mover><mi>P</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">]</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><msub><mi>Œ¥</mi><mn>1</mn></msub><mo>+</mo><msub><mi>W</mi><mn>1</mn></msub><msub><mi>Œ≤</mi><mn>1</mn></msub><mo>+</mo><mi>X</mi><msubsup><mi>Œ≤</mi><mn>1</mn><mi>X</mi></msubsup><mo>+</mo><msub><mi>Œ∫</mi><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>P</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
E[Y|D=0, W_0, X, \widehat{P}] &amp;= \delta_{0} + W_0 \beta_0 + X \beta^X_{0} + \kappa_0(\widehat{P}), \\
E[Y|D=0, W_1, X, \widehat{P}] &amp;= \delta_{1} + W_1 \beta_1 + X \beta^X_{1} + \kappa_1(\widehat{P}), 
\end{aligned}
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ∫</mi><mi>d</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>P</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\kappa_d(P)</annotation></semantics></math>
are <strong>control functions</strong>, equal to
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><msub><mi>Œ∫</mi><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>P</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>U</mi><mn>1</mn></msub><mo stretchy="false" form="prefix">|</mo><mi>D</mi><mo>=</mo><mn>1</mn><mo>,</mo><msub><mi>W</mi><mn>1</mn></msub><mo>,</mo><msub><mi>W</mi><mn>0</mn></msub><mo>,</mo><mi>X</mi><mo>,</mo><mi>P</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>U</mi><mn>1</mn></msub><mo stretchy="false" form="prefix">|</mo><mi>D</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>P</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>U</mi><mn>1</mn></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>U</mi><mi>D</mi></msub><mo>‚â§</mo><mi>P</mi><mo stretchy="true" form="postfix">]</mo></mrow></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"><msub><mi>Œ∫</mi><mn>0</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>P</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>U</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">|</mo><mi>D</mi><mo>=</mo><mn>0</mn><mo>,</mo><msub><mi>W</mi><mn>1</mn></msub><mo>,</mo><msub><mi>W</mi><mn>0</mn></msub><mo>,</mo><mi>X</mi><mo>,</mo><mi>P</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>U</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">|</mo><mi>D</mi><mo>=</mo><mn>0</mn><mo>,</mo><mi>P</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>U</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>U</mi><mi>D</mi></msub><mo>&gt;</mo><mi>P</mi><mo stretchy="true" form="postfix">]</mo></mrow><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
\kappa_1(P) &amp;= E[ U_1 | D=1, W_1, W_0, X,P] = E[U_1|D=1, P] = E[U_1 | U_D \leq P] \\
\kappa_0(P) &amp;= E[ U_0 | D=0, W_1, W_0, X,P] = E[U_0|D=0, P] = E[U_0 | U_D &gt; P].
\end{aligned}
</annotation></semantics></math> It is a <em>partially linear model</em>
because the control functions are nonparametric and can be estimated
more or less flexibly (see below).</p>
<p>Once the parameters
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ¥</mi><mi>d</mi></msub><mo>,</mo><msub><mi>Œ≤</mi><mi>d</mi></msub><mo>,</mo><msubsup><mi>Œ≤</mi><mi>d</mi><mi>X</mi></msubsup></mrow><annotation encoding="application/x-tex">\delta_d, \beta_d, \beta^X_d</annotation></semantics></math>
and the flexible control function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ∫</mi><mi>d</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\kappa_d()</annotation></semantics></math>
are estimated, we don‚Äôt need to estimate any other parameters to obtain
the MTE and MTR. We only need to also obtain the derivative from the
estimated
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Œ∫</mi><mi>d</mi></msub><annotation encoding="application/x-tex">\kappa_d</annotation></semantics></math>.
Indeed, define
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><msub><mover><mi>k</mi><mo accent="true">ÃÇ</mo></mover><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>U</mi><mn>1</mn></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>U</mi><mi>D</mi></msub><mo>=</mo><mi>u</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><msub><mover><mi>Œ∫</mi><mo accent="true">ÃÇ</mo></mover><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mi>u</mi><msub><mover><mi>Œ∫</mi><mo accent="true">ÃÇ</mo></mover><mn>1</mn></msub><mi>‚Ä≤</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"><msub><mover><mi>k</mi><mo accent="true">ÃÇ</mo></mover><mn>0</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>U</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>U</mi><mi>D</mi></msub><mo>=</mo><mi>u</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><msub><mover><mi>Œ∫</mi><mo accent="true">ÃÇ</mo></mover><mn>0</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àí</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>‚àí</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow><msub><mover><mi>Œ∫</mi><mo accent="true">ÃÇ</mo></mover><mn>0</mn></msub><mi>‚Ä≤</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
\widehat{k}_1(u) &amp;= E[ U_1 | U_D=u] = \widehat{\kappa}_1(u) + u \widehat{\kappa}_1'(u), \\
\widehat{k}_0(u) &amp;= E[ U_0 | U_D=u] = \widehat{\kappa}_0(u) - (1-u) \widehat{\kappa}_0'(u).
\end{aligned}
</annotation></semantics></math></p>
<p>Then, the <em>Marginal Treatment Responses</em> are given by:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><msub><mover><mrow><mi>M</mi><mi>T</mi><mi>R</mi></mrow><mo accent="true">ÃÇ</mo></mover><mi>d</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo>,</mo><msub><mi>w</mi><mi>d</mi></msub><mo>,</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>Y</mi><mi>d</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>X</mi><mo>=</mo><mi>x</mi><mo>,</mo><msub><mi>W</mi><mi>d</mi></msub><mo>=</mo><msub><mi>w</mi><mi>d</mi></msub><mo>,</mo><msub><mi>U</mi><mi>D</mi></msub><mo>=</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mover><mi>Œ¥</mi><mo accent="true">ÃÇ</mo></mover><mi>d</mi></msub><mo>+</mo><msub><mi>w</mi><mi>d</mi></msub><msub><mover><mi>Œ≤</mi><mo accent="true">ÃÇ</mo></mover><mi>d</mi></msub><mo>+</mo><mi>x</mi><msubsup><mover><mi>Œ≤</mi><mo accent="true">ÃÇ</mo></mover><mi>d</mi><mi>X</mi></msubsup><mo>+</mo><msub><mover><mi>k</mi><mo accent="true">ÃÇ</mo></mover><mi>d</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
\widehat{MTR}_d(u, w_d, x) &amp;= E(Y_d | X=x, W_d=w_d, U_D=u) = \widehat{\delta}_{d} + w_d \widehat{\beta}_d + x \widehat{\beta}^X_{d} + \widehat{k}_d(u)
\end{aligned}
</annotation></semantics></math></p>
<p>and the <em>Marginal Treatment Effects</em> are:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><mover><mrow><mi>M</mi><mi>T</mi><mi>E</mi></mrow><mo accent="true">ÃÇ</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo>,</mo><mi>x</mi><mo>,</mo><msub><mi>w</mi><mn>0</mn></msub><mo>,</mo><msub><mi>w</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mover><mrow><mi>M</mi><mi>T</mi><mi>R</mi></mrow><mo accent="true">ÃÇ</mo></mover><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo>,</mo><msub><mi>w</mi><mn>1</mn></msub><mo>,</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àí</mo><msub><mover><mrow><mi>M</mi><mi>T</mi><mi>R</mi></mrow><mo accent="true">ÃÇ</mo></mover><mn>0</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo>,</mo><msub><mi>w</mi><mn>0</mn></msub><mo>,</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
\widehat{MTE}(u, x, w_0, w_1) = \widehat{MTR}_1(u, w_1, x) - \widehat{MTR}_0(u, w_0, x).
\end{aligned}
</annotation></semantics></math></p>
<p>Consequently, the estimation is about estimating the parameters and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Œ∫</mi><mi>d</mi></msub><annotation encoding="application/x-tex">\kappa_d</annotation></semantics></math>.
Several estimation method <code>est_method</code> are implemented in
<code><a href="../reference/semiivreg.html">semiivreg()</a></code>. We describe them below. <br><br></p>
</div>
<div class="section level4">
<h4 id="method-1--double-residual-regression-robinson-1988">Method 1. Double residual regression, Robinson (1988)<a class="anchor" aria-label="anchor" href="#method-1--double-residual-regression-robinson-1988"></a>
</h4>
<p>The default method, implemented with
<code>est_method="locpoly"</code> is to run a <em>double residual
regression</em>, √† la <span class="citation">Robinson (1988)</span>, in
order to estimate the <em>partially linear model</em>. We implement it
similarly to the separate approach of <span class="citation">Andresen
(2018)</span> for the estimation of MTE with IVs. We estimate using a
<em>separate approach</em>, i.e., estimate separately on the treated and
untreated samples, by implementing the following steps:</p>
<ul>
<li><p><strong>Step 1.</strong> Estimate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>Y</mi><mi>d</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>D</mi><mo>=</mo><mi>d</mi><mo>,</mo><mover><mi>P</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">E(Y_d | D=d, \widehat{P})</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>W</mi><mi>d</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>D</mi><mo>=</mo><mi>d</mi><mo>,</mo><mover><mi>P</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">E(W_d | D=d, \widehat{P})</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>X</mi><mo stretchy="false" form="prefix">|</mo><mi>D</mi><mo>=</mo><mi>d</mi><mo>,</mo><mover><mi>P</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">E(X | D=d, \widehat{P})</annotation></semantics></math>
with a nonparametric local polynomial regression. To specify the
bandwidth of the local polynomial regression, use <code>bw0</code> or
<code>bw1</code>. If not specified, the bandwidth are automatically
computed using the method of <code>bw_method</code>. The default being a
fast <code>"plug-in"</code> method from the library
<code>KernSmooth</code>. We can also specify the degree of the
polynomial with <code>pol_degree_locpoly1</code>. By default, equal to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>1</mn><annotation encoding="application/x-tex">1</annotation></semantics></math>
as recommended in <span class="citation">Fan and Gijbels (2003)</span>
(order of the function we target
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">+1</annotation></semantics></math>).</p></li>
<li><p><strong>Step 2.</strong> On each subsample, compute the residuals
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><msub><mi>Y</mi><mi>d</mi></msub></msub><mo>=</mo><msub><mi>Y</mi><mi>d</mi></msub><mo>‚àí</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>Y</mi><mi>d</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>D</mi><mo>=</mo><mi>d</mi><mo>,</mo><mover><mi>P</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">e_{Y_d} = Y_d - E(Y_d | D=d, \widehat{P})</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><msub><mi>W</mi><mi>d</mi></msub></msub><mo>=</mo><msub><mi>W</mi><mi>d</mi></msub><mo>‚àí</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>W</mi><mi>d</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>D</mi><mo>=</mo><mi>d</mi><mo>,</mo><mover><mi>P</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">e_{W_d} = W_d - E(W_d | D=d, \widehat{P})</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>e</mi><mi>X</mi><mi>d</mi></msubsup><mo>=</mo><mi>X</mi><mo>‚àí</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>X</mi><mo stretchy="false" form="prefix">|</mo><mi>D</mi><mo>=</mo><mi>d</mi><mo>,</mo><mover><mi>P</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">e_X^d = X - E(X | D=d, \widehat{P})</annotation></semantics></math>.
Then, run the first residual regression, with a <strong>no-intercept
OLS</strong>:<br><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><msub><mi>Y</mi><mi>d</mi></msub></msub><mo>=</mo><msub><mi>e</mi><msub><mi>W</mi><mi>d</mi></msub></msub><msub><mi>Œ≤</mi><mi>d</mi></msub><mo>+</mo><msubsup><mi>e</mi><mi>X</mi><mi>d</mi></msubsup><msubsup><mi>Œ≤</mi><mi>d</mi><mi>X</mi></msubsup><mo>+</mo><msub><mover><mi>U</mi><mo accent="true">ÃÉ</mo></mover><mi>d</mi></msub><mi>.</mi></mrow><annotation encoding="application/x-tex"> e_{Y_d} = e_{W_d} \beta_d + e_X^d \beta^X_d + \tilde{U}_d. </annotation></semantics></math><br>
This regression on the subsample with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi><mo>=</mo><mi>d</mi></mrow><annotation encoding="application/x-tex">D=d</annotation></semantics></math>,
provides consistent estimates of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Œ≤</mi><mi>d</mi></msub><annotation encoding="application/x-tex">\beta_d</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>Œ≤</mi><mi>d</mi><mi>X</mi></msubsup><annotation encoding="application/x-tex">\beta^X_d</annotation></semantics></math>.<br>
Indeed, the residual equation is equivalent to<br><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Y</mi><mi>d</mi></msub><mo>‚àí</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>Y</mi><mi>d</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>D</mi><mo>=</mo><mi>d</mi><mo>,</mo><mover><mi>P</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>W</mi><mi>d</mi></msub><mo>‚àí</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>W</mi><mi>d</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>D</mi><mo>=</mo><mi>d</mi><mo>,</mo><mover><mi>P</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">]</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><msub><mi>Œ≤</mi><mi>d</mi></msub><mo>+</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>X</mi><mo>‚àí</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>X</mi><mo stretchy="false" form="prefix">|</mo><mi>D</mi><mo>=</mo><mi>d</mi><mo>,</mo><mover><mi>P</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">]</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><msubsup><mi>Œ≤</mi><mi>d</mi><mi>X</mi></msubsup><mo>+</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>U</mi><mi>d</mi></msub><mo>‚àí</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>U</mi><mi>d</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>D</mi><mo>=</mo><mi>d</mi><mo>,</mo><mover><mi>P</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">]</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex"> Y_d - E[Y_d | D=d, \widehat{P}] = (W_d - E[W_d | D=d, \widehat{P}]) \beta_d + E(X - E[X | D=d, \widehat{P}]) \beta_d^X + (U_d - E[U_d | D=d, \widehat{P}]). </annotation></semantics></math>
and if we denote
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>U</mi><mo accent="true">ÃÉ</mo></mover><mi>d</mi></msub><mo>=</mo><msub><mi>U</mi><mi>d</mi></msub><mo>‚àí</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>U</mi><mi>d</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>D</mi><mo>=</mo><mi>d</mi><mo>,</mo><mover><mi>P</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">\tilde{U}_d = U_d - E[U_d | D=d, \widehat{P}]</annotation></semantics></math>,
we have
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><msub><mover><mi>U</mi><mo accent="true">ÃÉ</mo></mover><mi>d</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>D</mi><mo>=</mo><mi>d</mi><mo>,</mo><mover><mi>P</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">E[\tilde{U}_d | D=d,  \widehat{P}] = 0</annotation></semantics></math>,
so the no-intercept residual OLS regression gives consistent
estimates.</p></li>
<li><p><strong>Step 3.</strong> Construct
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>Y</mi><mo accent="true">ÃÉ</mo></mover><mi>d</mi></msub><mo>=</mo><mi>Y</mi><mo>‚àí</mo><msub><mi>W</mi><mi>d</mi></msub><mover><msub><mi>Œ≤</mi><mi>d</mi></msub><mo accent="true">ÃÇ</mo></mover><mo>‚àí</mo><mi>X</mi><mover><msubsup><mi>Œ≤</mi><mi>d</mi><mi>X</mi></msubsup><mo accent="true">ÃÇ</mo></mover></mrow><annotation encoding="application/x-tex">\tilde{Y}_d = Y - W_d \widehat{\beta_d} - X \widehat{\beta^X_d}</annotation></semantics></math>,
on the sample with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi><mo>=</mo><mi>d</mi></mrow><annotation encoding="application/x-tex">D=d</annotation></semantics></math>,
i.e., the outcome <code>net of the effect</code> of the covariates. We
have
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>Y</mi><mo accent="true">ÃÉ</mo></mover><mi>d</mi></msub><mo>=</mo><msub><mi>Œ¥</mi><mi>d</mi></msub><mo>+</mo><msub><mi>U</mi><mi>d</mi></msub><mo>:=</mo><msub><mover><mi>Œ∫</mi><mo accent="true">ÃÉ</mo></mover><mi>d</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>P</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">\tilde{Y}_d = \delta_d + U_d := \tilde{\kappa}_d(P). </annotation></semantics></math></p></li>
<li><p><strong>Step 4.</strong> Estimate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>Œ∫</mi><mo accent="true">ÃÉ</mo></mover><mi>d</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>P</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\tilde{\kappa}_d(P)</annotation></semantics></math>
using a second nonparametric local polynomial regression of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>Y</mi><mo accent="true">ÃÉ</mo></mover><mi>d</mi></msub><annotation encoding="application/x-tex">\tilde{Y}_d</annotation></semantics></math>
on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>P</mi><annotation encoding="application/x-tex">P</annotation></semantics></math>.
To specify the bandwidth of the local polynomial regression, use
<code>bw_y0</code> or <code>bw_y1</code>. If not specified, the
bandwidth are automatically computed using the method of
<code>bw_method</code>. The default being a fast <code>"plug-in"</code>
method from the library <code>KernSmooth</code>. We can also specify the
degree of the polynomial with <code>pol_degree_locpoly2</code>. By
default, equal to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>2</mn><annotation encoding="application/x-tex">2</annotation></semantics></math>
as recommended in <span class="citation">Fan and Gijbels (2003)</span>
because we want to estimate the derivative,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>k</mi><mo accent="true">ÃÉ</mo></mover><mi>d</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>Œ¥</mi><mi>d</mi></msub><mo>+</mo><msub><mi>U</mi><mi>d</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>U</mi><mi>D</mi></msub><mo>=</mo><mi>u</mi><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">\tilde{k}_d(u) = E[\delta_d + U_d|U_D=u]</annotation></semantics></math>.
\ Once we have
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>Œ∫</mi><mo accent="true">ÃÉ</mo></mover><mi>d</mi></msub><annotation encoding="application/x-tex">\tilde{\kappa}_d</annotation></semantics></math>,
we can compute
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><msub><mover><mover><mi>k</mi><mo accent="true">ÃÉ</mo></mover><mo accent="true">ÃÇ</mo></mover><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>Œ¥</mi><mn>1</mn></msub><mo>+</mo><msub><mi>U</mi><mn>1</mn></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>U</mi><mi>D</mi></msub><mo>=</mo><mi>u</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><msub><mover><mover><mi>Œ∫</mi><mo accent="true">ÃÉ</mo></mover><mo accent="true">ÃÇ</mo></mover><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mi>u</mi><msub><mover><mover><mi>Œ∫</mi><mo accent="true">ÃÉ</mo></mover><mo accent="true">ÃÇ</mo></mover><mn>1</mn></msub><mi>‚Ä≤</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"><msub><mover><mover><mi>k</mi><mo accent="true">ÃÉ</mo></mover><mo accent="true">ÃÇ</mo></mover><mn>0</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>Œ¥</mi><mn>0</mn></msub><mo>+</mo><msub><mi>U</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>U</mi><mi>D</mi></msub><mo>=</mo><mi>u</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><msub><mover><mover><mi>Œ∫</mi><mo accent="true">ÃÉ</mo></mover><mo accent="true">ÃÇ</mo></mover><mn>0</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àí</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>‚àí</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow><msub><mover><mover><mi>Œ∫</mi><mo accent="true">ÃÉ</mo></mover><mo accent="true">ÃÇ</mo></mover><mn>0</mn></msub><mi>‚Ä≤</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
\widehat{\tilde{k}}_1(u) &amp;= E[ \delta_1 + U_1 | U_D=u] = \widehat{\tilde{\kappa}}_1(u) + u \widehat{\tilde{\kappa}}_1'(u), \\
\widehat{\tilde{k}}_0(u) &amp;= E[ \delta_0 + U_0 | U_D=u] = \widehat{\tilde{\kappa}}_0(u) - (1-u) \widehat{\tilde{\kappa}}_0'(u).
\end{aligned}
</annotation></semantics></math></p></li>
</ul>
<p>Using the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mover><mi>k</mi><mo accent="true">ÃÉ</mo></mover><mo accent="true">ÃÇ</mo></mover><mi>d</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\widehat{\tilde{k}}_d(u)</annotation></semantics></math>
and the estimated _d, ^X_d, we can compute the MTR on this subsample
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi><mo>=</mo><mi>d</mi></mrow><annotation encoding="application/x-tex">D=d</annotation></semantics></math>,
as
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><msub><mover><mrow><mi>M</mi><mi>T</mi><mi>R</mi></mrow><mo accent="true">ÃÇ</mo></mover><mi>d</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo>,</mo><msub><mi>w</mi><mi>d</mi></msub><mo>,</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>Y</mi><mi>d</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>X</mi><mo>=</mo><mi>x</mi><mo>,</mo><msub><mi>W</mi><mi>d</mi></msub><mo>=</mo><msub><mi>w</mi><mi>d</mi></msub><mo>,</mo><msub><mi>U</mi><mi>D</mi></msub><mo>=</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mi>w</mi><mi>d</mi></msub><msub><mover><mi>Œ≤</mi><mo accent="true">ÃÇ</mo></mover><mi>d</mi></msub><mo>+</mo><mi>x</mi><msubsup><mover><mi>Œ≤</mi><mo accent="true">ÃÇ</mo></mover><mi>d</mi><mi>X</mi></msubsup><mo>+</mo><msub><mover><mover><mi>k</mi><mo accent="true">ÃÉ</mo></mover><mo accent="true">ÃÇ</mo></mover><mi>d</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
\widehat{MTR}_d(u, w_d, x) &amp;= E(Y_d | X=x, W_d=w_d, U_D=u) = w_d \widehat{\beta}_d + x \widehat{\beta}^X_{d} + \widehat{\tilde{k}}_d(u).
\end{aligned}
</annotation></semantics></math><br>
Remark that the definition of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>Œ∫</mi><mo accent="true">ÃÉ</mo></mover><mi>d</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>P</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\tilde{\kappa}_d(P)</annotation></semantics></math>,
is equivalent to defining a more general shock that would include a
constant,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>U</mi><mo accent="true">ÃÉ</mo></mover><mi>d</mi></msub><mo>=</mo><msub><mi>Œ¥</mi><mi>d</mi></msub><mo>+</mo><msub><mi>U</mi><mi>d</mi></msub></mrow><annotation encoding="application/x-tex">\tilde{U}_d = \delta_d + U_d</annotation></semantics></math>.
This is innoccuous and yield the same MTR/MTE in the end.</p>
<p>Once the MTR are estimated separately on both subsample, we can
estimate the MTE:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><msub><mover><mrow><mi>M</mi><mi>T</mi><mi>R</mi></mrow><mo accent="true">ÃÇ</mo></mover><mi>d</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo>,</mo><msub><mi>w</mi><mi>d</mi></msub><mo>,</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>Y</mi><mi>d</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>X</mi><mo>=</mo><mi>x</mi><mo>,</mo><msub><mi>W</mi><mi>d</mi></msub><mo>=</mo><msub><mi>w</mi><mi>d</mi></msub><mo>,</mo><msub><mi>U</mi><mi>D</mi></msub><mo>=</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mi>w</mi><mi>d</mi></msub><msub><mover><mi>Œ≤</mi><mo accent="true">ÃÇ</mo></mover><mi>d</mi></msub><mo>+</mo><mi>x</mi><msubsup><mover><mi>Œ≤</mi><mo accent="true">ÃÇ</mo></mover><mi>d</mi><mi>X</mi></msubsup><mo>+</mo><msub><mover><mover><mi>k</mi><mo accent="true">ÃÉ</mo></mover><mo accent="true">ÃÇ</mo></mover><mi>d</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"><mover><mrow><mi>M</mi><mi>T</mi><mi>E</mi></mrow><mo accent="true">ÃÇ</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo>,</mo><mi>x</mi><mo>,</mo><msub><mi>w</mi><mn>0</mn></msub><mo>,</mo><msub><mi>w</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><msub><mover><mrow><mi>M</mi><mi>T</mi><mi>R</mi></mrow><mo accent="true">ÃÇ</mo></mover><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo>,</mo><msub><mi>w</mi><mn>1</mn></msub><mo>,</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àí</mo><msub><mover><mrow><mi>M</mi><mi>T</mi><mi>R</mi></mrow><mo accent="true">ÃÇ</mo></mover><mn>0</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo>,</mo><msub><mi>w</mi><mn>0</mn></msub><mo>,</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
\widehat{MTR}_d(u, w_d, x) &amp;= E(Y_d | X=x, W_d=w_d, U_D=u) = w_d \widehat{\beta}_d + x \widehat{\beta}^X_{d} + \widehat{\tilde{k}}_d(u) \\
\widehat{MTE}(u, x, w_0, w_1) &amp;= \widehat{MTR}_1(u, w_1, x) - \widehat{MTR}_0(u, w_0, x).
\end{aligned}
</annotation></semantics></math></p>
<p><em>Advantages.</em> The main advantage of this double residual
regression is that it is robust to misspecification of the nonparametric
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Œ∫</mi><mi>d</mi></msub><annotation encoding="application/x-tex">\kappa_d</annotation></semantics></math>
function, see <span class="citation">Robinson (1988)</span>. However, it
still requires to specify the bandwidths. In order to obtain the
standard errors around the estimates, given that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>P</mi><annotation encoding="application/x-tex">P</annotation></semantics></math>
is estimated in a first stage, we bootstrap the standard errors using
<code><a href="../reference/semiivreg.html">semiivreg_boot()</a></code>. This function takes longer than the
default estimation which is almost instantaneous. <br><br></p>
</div>
<div class="section level4">
<h4 id="method-2--sieve-estimation">Method 2. Sieve estimation<a class="anchor" aria-label="anchor" href="#method-2--sieve-estimation"></a>
</h4>
<p>An alternative method is to use sieve approach, implemented with
<code>est_method="sieve"</code>, to estimate the second stage. The idea
is simply to specify the control function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Œ∫</mi><mi>d</mi></msub><annotation encoding="application/x-tex">\kappa_d</annotation></semantics></math>
as a flexible function of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>P</mi><annotation encoding="application/x-tex">P</annotation></semantics></math>,
using flexible functional form.</p>
<p>By default we use polynomial transformation of degree
<code>pol_degree_sieve=5</code> for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ∫</mi><mn>0</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>P</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\kappa_0(P)</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ∫</mi><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>P</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\kappa_1(P)</annotation></semantics></math>.
Then, we estimate the second stage using a stacked regression of the
form:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>Y</mi><mo stretchy="false" form="prefix">|</mo><msub><mi>W</mi><mn>0</mn></msub><mo>,</mo><msub><mi>W</mi><mn>1</mn></msub><mo>,</mo><mi>X</mi><mo>,</mo><mover><mi>P</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo></mtd><mtd columnalign="left" style="text-align: left"><mi>D</mi><mo>√ó</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>Œ¥</mi><mn>1</mn></msub><mo>+</mo><msub><mi>W</mi><mn>1</mn></msub><msub><mi>Œ≤</mi><mn>1</mn></msub><mo>+</mo><mi>X</mi><msubsup><mi>Œ≤</mi><mn>1</mn><mi>X</mi></msubsup><mo>+</mo><msub><mi>Œ∫</mi><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>P</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"></mtd><mtd columnalign="left" style="text-align: left"><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>‚àí</mo><mi>D</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>√ó</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>Œ¥</mi><mn>0</mn></msub><mo>+</mo><msub><mi>W</mi><mn>0</mn></msub><msub><mi>Œ≤</mi><mn>0</mn></msub><mo>+</mo><mi>X</mi><msubsup><mi>Œ≤</mi><mn>0</mn><mi>X</mi></msubsup><mo>+</mo><msub><mi>Œ∫</mi><mn>0</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>P</mi><mo accent="true">ÃÇ</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
E[Y|W_0, W_1, X, \widehat{P}] = &amp;D \times ( \delta_{1} + W_1 \beta_1 + X \beta^X_{1} + \kappa_1(\widehat{P}) ) + \\
&amp;(1-D) \times ( \delta_{0} + W_0 \beta_0 + X \beta^X_{0} + \kappa_0(\widehat{P})).
\end{aligned}
</annotation></semantics></math> We do it as a stacked regression and
not separately in order to allow to restrict some covariates to have the
same effect on both potential outcomes (e.g.,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>Œ≤</mi><mn>0</mn><mi>X</mi></msubsup><mo>=</mo><msubsup><mi>Œ≤</mi><mn>1</mn><mi>X</mi></msubsup></mrow><annotation encoding="application/x-tex">\beta_0^X = \beta_1^X</annotation></semantics></math>).</p>
<p>Once we obtain
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>Œ∫</mi><mo accent="true">ÃÇ</mo></mover><mi>d</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>P</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\widehat{\kappa}_d(P)</annotation></semantics></math>,
we proceed as before to obtain
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>k</mi><mi>d</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">k_d(u)</annotation></semantics></math>
and the MTR/MTE. Because of the polynomial functional form,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>k</mi><mi>d</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">k_d(u)</annotation></semantics></math>
has a known functional form based on the estimated coefficients for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Œ∫</mi><mi>d</mi></msub><annotation encoding="application/x-tex">\kappa_d</annotation></semantics></math>,
so it is very easy to compute.</p>
<p><em>Advantages.</em> The main advantage of this sieve approach is
that it is faster and easier to implement (but <code>"locpoly"</code> is
also fast anyway). It also provides analytical standard errors. These
are wrong because they do not take into account that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>P</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\widehat{P}</annotation></semantics></math>
is estimated in a first stage, but, if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>P</mi><mo accent="true">ÃÇ</mo></mover><annotation encoding="application/x-tex">\widehat{P}</annotation></semantics></math>
is well estimated, the analytical standard errors should be very close
to the true one that we can obtain with the bootstrap in
<code><a href="../reference/semiivreg.html">semiivreg_boot()</a></code>.<br>
The disadvantage is that it is less robust to misspecification of the
control function as a polynomial. Even though, as visible in this <a href="https://cbruneelzupanc.github.io/semiIVreg/articles/semiIVreg_heterogenousTE.html">vignette</a>,
it still works well in our examples, even if the underlying
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Œ∫</mi><mi>d</mi></msub><annotation encoding="application/x-tex">\kappa_d</annotation></semantics></math>
is not a polynomial. <br><br></p>
</div>
<div class="section level4">
<h4 id="method-3--special-case-with-homogenous-treatment-effects">Method 3. Special Case with Homogenous Treatment Effects<a class="anchor" aria-label="anchor" href="#method-3--special-case-with-homogenous-treatment-effects"></a>
</h4>
<p>Using <code>est_method="homogenous"</code>, <code><a href="../reference/semiivreg.html">semiivreg()</a></code>
can also estimate a restricted model where we assume that the treatment
effects are <strong>homogenous</strong>, i.e., the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>T</mi><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo>,</mo><mi>x</mi><mo>,</mo><msub><mi>w</mi><mn>0</mn></msub><mo>,</mo><msub><mi>w</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>M</mi><mi>T</mi><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>,</mo><msub><mi>w</mi><mn>0</mn></msub><mo>,</mo><msub><mi>w</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">MTE(u, x, w_0, w_1) = MTE(x, w_0, w_1)</annotation></semantics></math>,
only varies with the observable covariates, but is constant with respect
to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>U</mi><mi>D</mi></msub><annotation encoding="application/x-tex">U_D</annotation></semantics></math>.
The homogenous treatment effect assumption is equivalent to imposing
that the underlying model corresponds to the general potential outcome
model (1)-(2), with the additional restriction that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>U</mi><mn>0</mn></msub><mo>=</mo><msub><mi>U</mi><mn>1</mn></msub><mo>=</mo><mi>U</mi></mrow><annotation encoding="application/x-tex">U_0 = U_1 = U</annotation></semantics></math>.</p>
<p>It is estimated using a procedure similar to the <code>sieve</code>
approach with heterogenous treatment effects, but where we impose
additional known restriction on the control functions
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ∫</mi><mn>0</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>P</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\kappa_0(P)</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ∫</mi><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>P</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\kappa_1(P)</annotation></semantics></math>
in the second stage estimation. Indeed,
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>U</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>0</mn><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>U</mi><mo stretchy="false" form="prefix">|</mo><msub><mi>U</mi><mi>D</mi></msub><mo>‚â§</mo><mi>P</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>P</mi><mo>+</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>U</mi><mo stretchy="false" form="prefix">|</mo><msub><mi>U</mi><mi>D</mi></msub><mo>&gt;</mo><mi>P</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>‚àí</mo><mi>P</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
E(U) = 0 = E(U | U_D \leq P) P + E(U | U_D &gt; P) (1-P)
</annotation></semantics></math></p>
<p>So,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œ∫</mi><mn>0</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>P</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mo>‚àí</mo><msub><mi>Œ∫</mi><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>P</mi><mo stretchy="true" form="postfix">)</mo></mrow><mfrac><mi>P</mi><mrow><mn>1</mn><mo>‚àí</mo><mi>P</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\kappa_0(P) = -\kappa_1(P) \frac{P}{1-P}</annotation></semantics></math>,
and one can check that it yields
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>k</mi><mn>0</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mi>k</mi><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>k</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">k_0(u) = k_1(u) = k(u)</annotation></semantics></math>.</p>
<p>Thus, the MTE is constant
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>k</mi><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àí</mo><msub><mi>k</mi><mn>0</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">k_1(u) - k_0(u) = 0</annotation></semantics></math>,
it cancels out), and equal to:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mrow><mi>M</mi><mi>T</mi><mi>E</mi></mrow><mo accent="true">ÃÇ</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>,</mo><msub><mi>w</mi><mn>0</mn></msub><mo>,</mo><msub><mi>w</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mover><mi>Œ¥</mi><mo accent="true">ÃÇ</mo></mover><mn>1</mn></msub><mo>‚àí</mo><msub><mover><mi>Œ¥</mi><mo accent="true">ÃÇ</mo></mover><mn>0</mn></msub><mo>+</mo><msub><mi>w</mi><mn>1</mn></msub><msub><mover><mi>Œ≤</mi><mo accent="true">ÃÇ</mo></mover><mn>1</mn></msub><mo>‚àí</mo><msub><mi>w</mi><mn>0</mn></msub><msub><mover><mi>Œ≤</mi><mo accent="true">ÃÇ</mo></mover><mn>0</mn></msub><mo>+</mo><mi>x</mi><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mover><mi>Œ≤</mi><mo accent="true">ÃÇ</mo></mover><mn>1</mn><mi>X</mi></msubsup><mo>‚àí</mo><msubsup><mover><mi>Œ≤</mi><mo accent="true">ÃÇ</mo></mover><mn>0</mn><mi>X</mi></msubsup><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">
\widehat{MTE}(x, w_0, w_1) = \widehat{\delta}_{1} - \widehat{\delta}_{0} + w_1 \widehat{\beta}_1 - w_0 \widehat{\beta}_0 + x (\widehat{\beta}^X_{1} - \widehat{\beta}^X_{0}).
</annotation></semantics></math></p>
<p>Note that the MTR still varies with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>u</mi><annotation encoding="application/x-tex">u</annotation></semantics></math>
because
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>u</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">k(u)</annotation></semantics></math>
is not constant, only the MTE is. <br><br></p>
</div>
<div class="section level4">
<h4 id="caution-about-the-estimated-standard-errors">Caution about the Estimated Standard Errors<a class="anchor" aria-label="anchor" href="#caution-about-the-estimated-standard-errors"></a>
</h4>
<p>By default, <code>est_method="sieve"</code> and
<code>"homogenous</code>‚Äù return <em>analytic standard errors</em>‚Ä¶ But
not accounting for the fact that the propensity score is estimated in a
first stage in <code>semiivreg</code>. Thus, these are wrong (but the
bias is very small if the first stage is well estimated, see <a href="https://cbruneelzupanc.github.io/semiIVreg/articles/semiIVreg_homogenousTE.html">these
simulations</a> for example).<br>
Use <code>semiivreg_boot</code> to obtain ‚Äòcorrect‚Äô bootstrapped
confidence intervals. <br><br></p>
</div>
</div>
</div>
<div class="section level2">
<h2 id="illustration-with-simulated-roy-model">Illustration with simulated Roy model<a class="anchor" aria-label="anchor" href="#illustration-with-simulated-roy-model"></a>
</h2>
<p>This illustrates what the <code><a href="../reference/semiivreg.html">semiivreg()</a></code>command reports for
a semi-IV regression. By default, it reports the common support plot of
the propensity score and the estimated marginal treatment effects
(MTE).</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://www.cbruneel.com/" class="external-link">semiIVreg</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">roydata</span><span class="op">)</span> <span class="co"># load the data from a simulated Roy model</span></span>
<span></span>
<span><span class="co"># semi-IV regression</span></span>
<span><span class="va">semiiv</span> <span class="op">=</span> <span class="fu"><a href="../reference/semiivreg.html">semiivreg</a></span><span class="op">(</span><span class="va">y</span><span class="op">~</span><span class="va">d</span><span class="op">|</span><span class="va">w0</span><span class="op">|</span><span class="va">w1</span>, data<span class="op">=</span><span class="va">roydata</span><span class="op">)</span> </span></code></pre></div>
<p><img src="semiIVreg_files/figure-html/mte-1.png" width="672" style="display: block; margin: auto;"></p>
<p>One can also easily extract a plot for the marginal treatment
responses (MTR):</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">semiiv</span><span class="op">$</span><span class="va">plot</span><span class="op">$</span><span class="va">mtr</span></span></code></pre></div>
<p><img src="semiIVreg_files/figure-html/mtr-1.png" width="480" style="display: block; margin: auto;"></p>
<p>For more details, see the vignettes on estimation with <a href="https://cbruneelzupanc.github.io/semiIVreg/articles/semiIVreg_heterogenousTE.html">heterogenous</a>
or <a href="https://cbruneelzupanc.github.io/semiIVreg/articles/semiIVreg_homogenousTE.html">homogenous</a>
treatment effects. Refer also to <span class="citation">Bruneel-Zupanc
(2024)</span>.</p>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-andresen2018exploring" class="csl-entry">
Andresen, Martin Eckhoff. 2018. <span>‚ÄúExploring Marginal Treatment
Effects: Flexible Estimation Using Stata.‚Äù</span> <em>The Stata
Journal</em> 18 (1): 118‚Äì58.
</div>
<div id="ref-brinch2017beyond" class="csl-entry">
Brinch, Christian N, Magne Mogstad, and Matthew Wiswall. 2017.
<span>‚ÄúBeyond LATE with a Discrete Instrument.‚Äù</span> <em>Journal of
Political Economy</em> 125 (4): 985‚Äì1039.
</div>
<div id="ref-bruneel2024" class="csl-entry">
Bruneel-Zupanc, Christophe. 2024. <span>‚ÄúDon‚Äôt (Fully) Exclude Me, It‚Äôs
Not Necessary! Identification with Semi-IVs.‚Äù</span> <a href="https://arxiv.org/abs/2303.12667" class="external-link">https://arxiv.org/abs/2303.12667</a>.
</div>
<div id="ref-carneiroheckmanvytlacil2011" class="csl-entry">
Carneiro, Pedro, James J. Heckman, and Edward J. Vytlacil. 2011.
<span>‚ÄúEstimating Marginal Returns to Education.‚Äù</span> <em>The
American Economic Review</em> 101 (6): 2754‚Äì81. <a href="http://www.jstor.org/stable/23045657" class="external-link">http://www.jstor.org/stable/23045657</a>.
</div>
<div id="ref-fangijbels2003" class="csl-entry">
Fan, Jianqing., and Ir√®ne. Gijbels. 2003. <em>Local Polynomial Modelling
and Its Applications.</em> Monographs on Statistics and Applied
Probability 66. Boca Raton: Chapman; Hall/CRC.
</div>
<div id="ref-robinson1988root" class="csl-entry">
Robinson, Peter M. 1988. <span>‚ÄúRoot-n-Consistent Semiparametric
Regression.‚Äù</span> <em>Econometrica: Journal of the Econometric
Society</em>, 931‚Äì54.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Christophe Bruneel.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
